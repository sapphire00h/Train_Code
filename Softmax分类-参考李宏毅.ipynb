{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da02bb7-867a-4ec6-ace8-c2d9ed87efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Operations\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Reading/Writing Data\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# For Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pytorch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "# For plotting learning curve\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c90e83b-d1cb-4671-9be4-eddf0587a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "config = {\n",
    "    'seed': 5201314,      # Your seed number, you can pick your lucky number. :)\n",
    "    'select_all': False,   # Whether to use all features.\n",
    "    'valid_ratio': 0.1,   # validation_size = train_size * valid_ratio\n",
    "    'n_epochs': 3000,     # Number of epochs.            \n",
    "    'batch_size': 1024, \n",
    "    'learning_rate': 1e-3,  #10的负5次方            \n",
    "    'early_stop': 400,    # If model has not improved for this many consecutive epochs, stop training.     \n",
    "    'save_path': './models/model.ckpt'  # Your model will be saved here.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff9b4c6-f505-489c-b95e-dca09a3ddcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    '''\n",
    "    x: Features.\n",
    "    y: Targets, if none, do prediction.\n",
    "    '''\n",
    "    def __init__(self, x, y=None):\n",
    "        #如果y为None，则表示没有目标数据，只进行预测。\n",
    "        if y is None:\n",
    "            self.y = y\n",
    "        else:\n",
    "            self.y = torch.FloatTensor(y)\n",
    "            \n",
    "        self.x = torch.FloatTensor(x)\n",
    "    #获取数据集中特定索引（idx）的样本。\n",
    "    def __getitem__(self, idx):\n",
    "        #如果self.y为None，表示只进行预测，此时返回self.x[idx]，即返回特征数据。\n",
    "        if self.y is None:\n",
    "            return self.x[idx]\n",
    "        else:\n",
    "            return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d19012-e821-4735-9e8f-7e6a1746cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feat(train_data, valid_data, test_data, select_all=True):\n",
    "    #从训练数据集和验证数据集中提取目标数据，假设目标数据位于每个数据集的最后一列。 :：表示选择所有的行。-1：表示选择最后一列。\n",
    "    y_train, y_valid = train_data[:,1], valid_data[:,1]\n",
    "    \n",
    "    #[0] + list(range(2, 50))\n",
    "    raw_x_train, raw_x_valid, raw_x_test = train_data[:,[0] + list(range(2, 82))], valid_data[:,[0] + list(range(2, 82))], test_data\n",
    "    \n",
    "    #创建一个包含所有特征列的索引列表\n",
    "    if select_all:\n",
    "        feat_idx = list(range(raw_x_train.shape[1]))\n",
    "    else:\n",
    "        feat_idx = list(range(1,81))\n",
    "  \n",
    "    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435fa41-47cc-41a6-8770-0d915b4eed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seed(seed): \n",
    "    #A bool that, if True, causes cuDNN to only use deterministic convolution algorithms.确定性卷积算法\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    #A bool that, if True, causes cuDNN to benchmark multiple convolution algorithmsand select the fastest.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    #设置CUDA的随机数生成器的种子.通过设置相同的种子，确保了在相同的种子下，使用CUDA生成的随机数也是一致的。\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "#valid_ratio=0.2,data_set=train_data       \n",
    "def train_valid_split(data_set, valid_ratio, seed):\n",
    "    '''Split provided training data into training set and validation set'''\n",
    "    valid_set_size = int(valid_ratio * len(data_set)) \n",
    "    train_set_size = len(data_set) - valid_set_size\n",
    "    #使用random_split函数将数据集划分为训练集和验证集，并将它们分配给train_set和valid_set变量。\n",
    "    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
    "    return np.array(train_set), np.array(valid_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf02dd-5c41-4bb1-9759-edb3acfb231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置随机种子\n",
    "same_seed(config['seed'])\n",
    "\n",
    "\n",
    "train_data, test_data = pd.read_csv('../output/数据/train_data.csv').values, pd.read_csv('../output/数据/tt_data.csv').values\n",
    "#使用train_data来划分训练集和验证集\n",
    "train_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n",
    "# Print out the data size.将划分的结果打印出来\n",
    "print(f\"\"\"train_data size: {train_data.shape} \n",
    "valid_data size: {valid_data.shape} \n",
    "test_data size: {test_data.shape}\"\"\")\n",
    "\n",
    "x_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, config['select_all'])\n",
    "\n",
    "# Print out the number of features.\n",
    "print(f'number of features: {x_train.shape[1]}')\n",
    "\n",
    "#创建自定义数据集对象，即你的数据集需要继承自torch.utils.data.Dataset类，并实现__len__和__getitem__方法。\n",
    "train_dataset, valid_dataset, test_dataset = Dataset(x_train, y_train),Dataset(x_valid, y_valid),Dataset(x_test)\n",
    "\n",
    "# Pytorch data loader loads pytorch dataset into batches.\n",
    "'''\n",
    "在PyTorch的DataLoader中，pin_memory是一个参数，用于控制是否将加载的数据存储在固定内存中。\n",
    "当pin_memory=True时，数据将被存储在固定内存（pinned memory）中，这对于使用GPU加速训练过程非常有用。\n",
    "当pin_memory=True时，DataLoader将会在返回每个批次的数据之前，将数据从主机内存（host memory）复制到固定内存。\n",
    "这样可以减少从主机内存到GPU内存的数据传输时间，从而加快训练过程。\n",
    "但是，需要注意的是，如果你的数据集非常大，将所有数据复制到固定内存可能会导致内存不足的问题。\n",
    "因此，在使用pin_memory=True时，确保你的系统具有足够的固定内存可供使用。\n",
    "'''\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f7177a-53f5-4b31-89e2-727725914203",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02aaedf-878c-4458-bd6d-77a56a9b8d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(My_Model, self).__init__()\n",
    "        # TODO: modify model's structure, be aware of dimensions. \n",
    "        self.layers = nn.Sequential(\n",
    "            #nn.Linear(input_dim, 256),\n",
    "            #nn.LeakyReLU(negative_slope=0.01),\n",
    "            #nn.Dropout(p=0.4),\n",
    "            #nn.Linear(256,256),\n",
    "            #nn.LeakyReLU(negative_slope=0.01),\n",
    "            #nn.Dropout(p=0.2),\n",
    "            #nn.Linear(256, 16),\n",
    "            #nn.LeakyReLU(negative_slope=0.01),\n",
    "            #nn.Dropout(p=0.2),\n",
    "            #nn.Linear(16,2)\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),  # 添加批量归一化\n",
    "            nn.ReLU(),  # 更换为ReLU激活函数\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(256,128), # 调整隐藏层神经元数量\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2), # 调整dropout率\n",
    "            nn.Linear(128, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(16,2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        #x = x.squeeze(1) # (B, 1) -> (B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e3e5c8-f554-448a-9e35-2807a385cbb1",
   "metadata": {},
   "source": [
    "### trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bf0c1a-75be-40b3-a094-2521a70fd23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(train_loader, valid_loader, model, config, device):\n",
    "    criterion =nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'],weight_decay = 0.001)\n",
    "    \n",
    "    # Writer of tensoboard.\n",
    "    #writer = SummaryWriter() \n",
    "\n",
    "    if not os.path.isdir('./models'):\n",
    "        os.mkdir('./models') # Create directory of saving models.\n",
    "\n",
    "    #初始化参数\n",
    "    n_epochs=config['n_epochs']\n",
    "    best_loss=math.inf\n",
    "    step=0\n",
    "    early_stop_count=0\n",
    "    \n",
    "    #开始训练\n",
    "    for epoch in range(n_epochs):\n",
    "        #设置训练模式\n",
    "        model.train() \n",
    "        #创建了一个空列表loss_record，用于存储每个训练批次的损失值。\n",
    "        loss_record = []\n",
    "        # tqdm is a package to visualize your training progress.用于训练进度显示与加载训练集\n",
    "        train_pbar = tqdm(train_loader, position=0, leave=True)\n",
    "        for X, y in train_pbar:\n",
    "            #设置零度归零\n",
    "            optimizer.zero_grad()              \n",
    "            X, y = X.to(device), y.to(device)   \n",
    "            pred = model(X)\n",
    "            #使用交叉熵计算loss        \n",
    "            loss = criterion(pred, y.to(torch.int64))\n",
    "            #loss反向传播\n",
    "            loss.backward()                     # Compute gradient(backpropagation).\n",
    "            #进行优化，根据计算得到的梯度更新模型的参数。\n",
    "            optimizer.step()                    # Update parameters.\n",
    "            step += 1\n",
    "            loss_record.append(loss.detach().item())\n",
    "            # 可视化训练过程\n",
    "            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "            train_pbar.set_postfix({'loss': loss.detach().item()})\n",
    "        #平均训练损失值。    \n",
    "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
    "        \n",
    "        #保存训练Loss\n",
    "        #writer.add_scalar('Loss/train', mean_train_loss, step)\n",
    "        \n",
    "        model.eval() # Set your model to evaluation mode.\n",
    "        loss_record = []\n",
    "        #开始验证\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            #取消梯度计算\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                loss = criterion(pred, y.to(torch.int64))\n",
    "            loss_record.append(loss.item())\n",
    "        \n",
    "        #计算平均测试损失值    \n",
    "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
    "        \n",
    "        #保存验证Loss\n",
    "        #writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
    "        \n",
    "        #writer.close()\n",
    "\n",
    "        if mean_valid_loss < best_loss:\n",
    "            best_loss = mean_valid_loss\n",
    "            torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
    "            print('Saving model with loss {:.3f}...'.format(best_loss))\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count += 1\n",
    "\n",
    "        if early_stop_count >= config['early_stop']:\n",
    "            print('\\nModel is not improving, so we halt the training session.')\n",
    "            writer.close()\n",
    "            return\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fc32e1-0435-4992-82e2-36767aef6473",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fadce48-85ac-49ea-bb91-02cf06784ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数值初始化\n",
    "def init_weights(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.normal_(m.weight,std=0.01)\n",
    "    \n",
    "model = My_Model(input_dim=x_train.shape[1]).to(device) # put your model and data on the same computation device.\n",
    "model.apply(init_weights);\n",
    "#model.apply(xavier_he_init);\n",
    "trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c26be7-1ca8-4180-9076-4b98a531abb3",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057196d-0cbf-46ce-8c04-e2591cf99789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_loader, model, device, id_list):\n",
    "    model.eval() # Set your model to evaluation mode.\n",
    "    preds = []\n",
    "    for x in tqdm(test_loader):\n",
    "        x = x.to(device)                        \n",
    "        with torch.no_grad():\n",
    "            pred_probs = torch.softmax(model(x), dim=1)\n",
    "            #pred_probs =model(x)\n",
    "            #print(pred_probs)\n",
    "            preds.append(pred_probs.detach().cpu())   \n",
    "    preds = torch.cat(preds, dim=0).numpy()\n",
    "\n",
    "    # Convert the predicted probabilities to the final format\n",
    "    results = []\n",
    "    for i, id_no in enumerate(id_list):\n",
    "        # pred_type = preds[i].argmax()  # Get the predicted class index (0 or 1)\n",
    "        pred_type = preds[i].argmax()  # Get the predicted class index (0 or 1)\n",
    "        #print(pred_type)\n",
    "        pred_prob = preds[i, pred_type]  # Get the predicted probability for the predicted class\n",
    "        results.append([id_no, pred_type.item(), pred_prob.item()])\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dcd739-e8da-4473-91de-902b5b2f5a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_decimal(num):\n",
    "    # Convert a number from scientific notation to a string with 13 decimal places\n",
    "    return \"{:.13f}\".format(num)\n",
    "\n",
    "def save_pred(preds, file):\n",
    "    ''' Save predictions to the specified file '''\n",
    "    with open(file, 'w', newline='') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['id_no', 'predtype', 'predprob'])\n",
    "        for pred in preds:\n",
    "            id_no = pred[0]  # Convert ID number to scientific notation\n",
    "            pred_type = pred[1]  # Predicted class index\n",
    "            if pred_type==0:\n",
    "                pred_prob = 1.0-pred[2] # Format predicted probability\n",
    "            else:\n",
    "                #pred_prob =format_scientific_notation(pred[2])\n",
    "                pred_prob =pred[2]\n",
    "            #pred_prob =pred[2]\n",
    "            #pred_prob = format_decimal(pred_prob)\n",
    "            writer.writerow([id_no, pred_type, pred_prob])\n",
    "\n",
    "\n",
    "df = pd.read_csv('./test_data.csv')\n",
    "id_list = df.iloc[:, 0].values.tolist()        \n",
    "model = My_Model(input_dim=x_train.shape[1]).to(device)\n",
    "model.load_state_dict(torch.load(config['save_path']))\n",
    "preds = predict(test_loader, model, device,id_list) \n",
    "#print(preds)\n",
    "save_pred(preds, 'pred.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63efa660-c527-4f30-a6df-abbb7e19177e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf65cb-2ff3-4753-9650-e3c5afa394f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
